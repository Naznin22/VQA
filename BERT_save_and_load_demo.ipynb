{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_owEX5aiZxR-"
      },
      "source": [
        "train_path = '/content/OpenEnded_mscoco_train2014_questions.json'\n",
        "val_path = '/content/OpenEnded_mscoco_val2014_questions.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYd3DeTTLNE-",
        "outputId": "c850e2dd-eef7-454e-d39e-56c46c5c1d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.9)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.2)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.9->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7KwDMQKOp3c"
      },
      "source": [
        "import torch\n",
        "\n",
        "def embed(text, tokenizer, model):\n",
        "  # Load pre-trained model tokenizer (vocabulary)\n",
        "  #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "  # Tokenize our sentence with the BERT tokenizer.\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "  # Map the token strings to their vocabulary indeces.\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "  # Convert inputs to PyTorch tensors\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  # Load pre-trained model (weights)\n",
        "  #model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "  model.eval()\n",
        "\n",
        "  # Predict hidden states features for each layer\n",
        "  with torch.no_grad():\n",
        "      encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "  # `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
        "\n",
        "  # `token_vecs` is a tensor with shape [22 x 768]\n",
        "  token_vecs = encoded_layers[11][0]\n",
        "\n",
        "  # Calculate the average of all 22 token vectors.\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "  return sentence_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrC5GX8GWcHg"
      },
      "source": [
        "import json\n",
        "with open(train_path, 'r') as fd:\n",
        "            questions_json = json.load(fd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLGw9VPzLA2S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "8220bd68-d9a5-4fa8-bfa3-f0e94081fa33"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "h5_file = h5py.File('/content/drive/My Drive/Colab Notebooks/qa_path/train_q_real.h5', 'w')\n",
        "data = h5_file.create_dataset('data', shape=(248349, 768), dtype=np.float64, fillvalue=0)\n",
        "\n",
        "def prepare_questions(questions_json):\n",
        "    questions = [q['question'] for q in questions_json['questions']]\n",
        "    #print(len(questions))\n",
        "    counter=0\n",
        "    for question in questions:\n",
        "        counter+=1\n",
        "        if(counter%1000 == 0):\n",
        "          print('Processed '+(str)(counter)+' questions')\n",
        "        question = question.lower()[:-1]\n",
        "        data[counter-1] = embed(question, tokenizer, model)\n",
        "\n",
        "prepare_questions(questions_json)\n",
        "h5_file.close()\n",
        "questions = list(prepare_questions(questions_json))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed 1000 questions\n",
            "Processed 2000 questions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-843579fde8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprepare_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mh5_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-843579fde8ec>\u001b[0m in \u001b[0;36mprepare_questions\u001b[0;34m(questions_json)\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processed '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' questions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprepare_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7ef401793cb8>\u001b[0m in \u001b[0;36membed\u001b[0;34m(text, tokenizer, model)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m# Predict hidden states features for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0;31m# `encoded_layers` has shape [12 x 1 x 22 x 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJHEJEsWtIy"
      },
      "source": [
        "data = h5py.File('/content/drive/My Drive/Colab Notebooks/qa_path/val_q.h5', 'r')\n",
        "ar = data['data'][1]\n",
        "#print(ar)\n",
        "t = torch.tensor(ar)\n",
        "#print(t)\n",
        "#print(t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CVAYFStxXb7",
        "outputId": "439a6522-5faa-41ba-ae53-4e44f3c067ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "qs = [ torch.tensor(q, dtype=torch.float64) for q in data['data'] ]\n",
        "print(len(qs))\n",
        "print(qs[0].shape)\n",
        "print(qs[0][:5])\n",
        "print(qs[1105][:5])\n",
        "print(qs[29997][:5])\n",
        "print(qs[29998][:5])\n",
        "print(qs[29999][:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000\n",
            "torch.Size([768])\n",
            "tensor([-0.0660, -0.3230, -0.0460, -0.0660,  0.4901], dtype=torch.float64)\n",
            "tensor([-0.1644,  0.1507, -0.0917,  0.1274,  0.1025], dtype=torch.float64)\n",
            "tensor([ 0.2105,  0.1708, -0.0801,  0.0617,  0.7281], dtype=torch.float64)\n",
            "tensor([ 0.5266,  0.1481,  0.1471, -0.3032,  0.0594], dtype=torch.float64)\n",
            "tensor([-0.1489, -0.1921, -0.0801,  0.0474,  0.5805], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWKb09leL3ym",
        "outputId": "ef698442-382b-4807-dd0a-c3578e536ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(questions[2])\n",
        "tensor1 = (embed(questions[2], tokenizer, model))\n",
        "tensor2 = (embed(questions[3], tokenizer, model))\n",
        "\n",
        "for i in range(768):\n",
        "    print('{} {}'.format(tensor1[i],tensor2[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "where is the man sitting\n",
            "-0.03696434944868088 0.14837650954723358\n",
            "0.015437464229762554 0.051264435052871704\n",
            "0.06961556524038315 0.05781183019280434\n",
            "0.12220525741577148 -0.059995394200086594\n",
            "0.47545671463012695 0.6131995320320129\n",
            "-0.030782027170062065 0.22683154046535492\n",
            "-0.02510000951588154 -0.1252213567495346\n",
            "0.48267969489097595 0.3875361382961273\n",
            "-0.21593043208122253 -0.18538688123226166\n",
            "-0.17462347447872162 -0.2633647620677948\n",
            "0.06435434520244598 0.4358271062374115\n",
            "-0.039950426667928696 -0.08932927250862122\n",
            "0.013003461062908173 -0.13226664066314697\n",
            "0.14126846194267273 0.15925373136997223\n",
            "-0.1895371526479721 -0.16804616153240204\n",
            "0.4259328544139862 0.35926368832588196\n",
            "0.23532511293888092 0.3785689175128937\n",
            "-0.10232572257518768 0.15112869441509247\n",
            "0.023811692371964455 0.05412256345152855\n",
            "0.4691171646118164 0.22333437204360962\n",
            "0.055501848459243774 0.2949240207672119\n",
            "0.15813598036766052 0.027374267578125\n",
            "-0.06388293951749802 0.038222070783376694\n",
            "-0.24216338992118835 0.024987583979964256\n",
            "0.34014061093330383 0.3087841272354126\n",
            "0.15925419330596924 0.2873934507369995\n",
            "-0.19494254887104034 -0.16237735748291016\n",
            "0.1616400182247162 0.2766278088092804\n",
            "0.0010338510619476438 0.3937632739543915\n",
            "-0.15894107520580292 -0.18635106086730957\n",
            "-0.0985342413187027 0.3123073875904083\n",
            "-0.27557581663131714 -0.2748863399028778\n",
            "-0.09627775102853775 -0.04808501526713371\n",
            "-0.17719848453998566 -0.07024206966161728\n",
            "-0.1069469302892685 -0.23992043733596802\n",
            "0.06402985751628876 -0.440825492143631\n",
            "-0.18569840490818024 -0.21585385501384735\n",
            "-0.19755706191062927 -0.32673272490501404\n",
            "-0.21387925744056702 -0.40226057171821594\n",
            "0.014078370295464993 0.04802136495709419\n",
            "-0.5306083559989929 -0.4488842487335205\n",
            "-0.329555481672287 -0.34157779812812805\n",
            "0.2411876618862152 0.10432382673025131\n",
            "0.245522141456604 0.28770774602890015\n",
            "-0.3007313907146454 -0.4340914785861969\n",
            "-0.34546539187431335 -0.40500473976135254\n",
            "0.25405335426330566 0.21005238592624664\n",
            "-0.1359478086233139 0.10088106244802475\n",
            "-0.08799351751804352 -0.355646014213562\n",
            "0.21268732845783234 0.22388668358325958\n",
            "-0.152309849858284 0.1283165067434311\n",
            "0.34370866417884827 0.16699464619159698\n",
            "-0.35324549674987793 -0.4479941427707672\n",
            "0.16262544691562653 0.12746725976467133\n",
            "0.3693212866783142 0.07994784414768219\n",
            "0.2917390763759613 0.4988536834716797\n",
            "0.14389048516750336 -0.36252260208129883\n",
            "-0.22096970677375793 -0.29798468947410583\n",
            "-0.20556508004665375 -0.030631976202130318\n",
            "-0.018238967284560204 0.15042977035045624\n",
            "0.2989226281642914 0.5634891390800476\n",
            "-0.1308964639902115 -0.11198964715003967\n",
            "0.029735539108514786 -0.034414637833833694\n",
            "-0.5373291373252869 -0.5296080708503723\n",
            "-0.05031494423747063 0.12966620922088623\n",
            "0.1429189294576645 0.40016427636146545\n",
            "0.10012165457010269 0.0806814432144165\n",
            "0.22417251765727997 0.18332087993621826\n",
            "-0.30295607447624207 -0.19432836771011353\n",
            "0.34474197030067444 0.22122906148433685\n",
            "-0.2981759011745453 -0.12349158525466919\n",
            "-0.38840028643608093 -0.5552323460578918\n",
            "0.36114582419395447 0.3367719352245331\n",
            "0.012979504652321339 0.3917417824268341\n",
            "-0.13496200740337372 -0.12714160978794098\n",
            "-0.2437310665845871 0.227873757481575\n",
            "-0.1924102008342743 -0.30707648396492004\n",
            "0.3513423502445221 0.2836121618747711\n",
            "-0.1541675180196762 -0.03543957695364952\n",
            "-0.010968736372888088 0.18583087623119354\n",
            "-0.08577460050582886 -0.17573124170303345\n",
            "0.1330956071615219 0.43608877062797546\n",
            "-0.45480528473854065 -0.05235254764556885\n",
            "0.4924760162830353 0.486100435256958\n",
            "0.09859993308782578 0.0021651138085871935\n",
            "-0.001194555894471705 0.24636828899383545\n",
            "-0.2047877162694931 -0.12420379370450974\n",
            "-0.05799659341573715 0.10196232795715332\n",
            "0.10625425726175308 0.02804773859679699\n",
            "0.5345178842544556 0.24955888092517853\n",
            "0.12044505029916763 0.35911479592323303\n",
            "0.09633028507232666 -0.05701695755124092\n",
            "-0.23190678656101227 0.14018398523330688\n",
            "0.0640658289194107 -0.029658950865268707\n",
            "-0.08053692430257797 0.02700118161737919\n",
            "-0.006890254560858011 0.014415700919926167\n",
            "0.21710304915905 0.005493124481290579\n",
            "-0.10957175493240356 -0.2352890521287918\n",
            "-0.2125415802001953 -0.2710074186325073\n",
            "0.31417199969291687 0.12830853462219238\n",
            "0.19887807965278625 -0.052751485258340836\n",
            "-0.4238738417625427 -0.21592555940151215\n",
            "0.11194201558828354 0.08936681598424911\n",
            "0.1995844542980194 0.3211272060871124\n",
            "-0.021911803632974625 0.12432859092950821\n",
            "-0.2001270353794098 -0.15220816433429718\n",
            "0.5138682126998901 0.34343740344047546\n",
            "0.4333129823207855 0.3384999930858612\n",
            "0.18585316836833954 0.31652122735977173\n",
            "-0.48697900772094727 -0.41022351384162903\n",
            "0.032100506126880646 0.36316201090812683\n",
            "-0.1951213926076889 0.023274466395378113\n",
            "0.07285250723361969 0.22251825034618378\n",
            "-0.1588059514760971 0.001780455349944532\n",
            "-0.07660450786352158 -0.1964455246925354\n",
            "0.4206129014492035 0.39252975583076477\n",
            "0.37017005681991577 0.2934163808822632\n",
            "-0.2620093524456024 -0.31793394684791565\n",
            "-0.03664593771100044 -0.22400103509426117\n",
            "0.303474485874176 -0.27318906784057617\n",
            "-0.12101082503795624 0.18474553525447845\n",
            "0.06976686418056488 0.05555470660328865\n",
            "0.048482708632946014 0.2299765795469284\n",
            "0.8902052640914917 0.6604364514350891\n",
            "0.10628128051757812 0.05611919239163399\n",
            "0.1817009299993515 0.04552900791168213\n",
            "-0.23995976150035858 0.07264751940965652\n",
            "-0.2158023566007614 0.019394835457205772\n",
            "-0.08865082263946533 0.1910010725259781\n",
            "-0.5185543894767761 -0.499936580657959\n",
            "0.17762170732021332 0.22777850925922394\n",
            "0.08864375203847885 0.28223586082458496\n",
            "0.2543504536151886 0.08047228306531906\n",
            "-0.19660112261772156 -0.21550250053405762\n",
            "-0.30411115288734436 -0.5498123168945312\n",
            "0.38566845655441284 0.41279682517051697\n",
            "-0.17291763424873352 -0.04295259341597557\n",
            "-0.04537389427423477 -0.41336408257484436\n",
            "-0.5392080545425415 -0.7097222805023193\n",
            "0.236588254570961 0.08558633923530579\n",
            "0.04180793836712837 0.0944071114063263\n",
            "0.01958385482430458 0.34229961037635803\n",
            "-0.31925728917121887 -0.06534182280302048\n",
            "0.10835813730955124 0.26091837882995605\n",
            "0.2457849681377411 0.010645643807947636\n",
            "-0.13398045301437378 0.06251794099807739\n",
            "-0.12179689109325409 0.0646391436457634\n",
            "0.11503704637289047 0.2714776396751404\n",
            "0.39509788155555725 0.23122280836105347\n",
            "-0.1655472069978714 -0.4118482172489166\n",
            "-0.008216866292059422 0.15129190683364868\n",
            "0.301226943731308 0.0030611902475357056\n",
            "0.29011771082878113 0.3422473967075348\n",
            "-0.3513084948062897 -0.22456574440002441\n",
            "-0.11509628593921661 -0.14056812226772308\n",
            "0.03151588514447212 0.028490006923675537\n",
            "-0.08249596506357193 -0.25818243622779846\n",
            "-0.036757249385118484 -0.3043968379497528\n",
            "0.26982003450393677 0.5138326287269592\n",
            "0.025350818410515785 -0.05681611970067024\n",
            "0.20093639194965363 0.16974355280399323\n",
            "-0.2406788170337677 -0.31883642077445984\n",
            "-0.3037751615047455 -0.1321059763431549\n",
            "0.08153515309095383 0.1140308678150177\n",
            "0.14417019486427307 -0.13735485076904297\n",
            "-0.13298264145851135 -0.04474111273884773\n",
            "0.15868684649467468 0.3908901512622833\n",
            "0.3924958407878876 0.20573949813842773\n",
            "0.11914938688278198 -0.02043895795941353\n",
            "0.018488237634301186 -0.05700279399752617\n",
            "0.01400922890752554 0.2312595397233963\n",
            "-0.09174466133117676 -0.007188985589891672\n",
            "0.5287430882453918 0.42495426535606384\n",
            "-0.14391915500164032 -0.0738038718700409\n",
            "-0.24672886729240417 -0.28176674246788025\n",
            "-0.18537582457065582 -0.5256163477897644\n",
            "-0.00928706768900156 0.0714222714304924\n",
            "-0.030067261308431625 0.24021051824092865\n",
            "0.3035569489002228 0.1981005221605301\n",
            "-0.23971550166606903 0.3366871178150177\n",
            "-1.392696499824524 -1.4825925827026367\n",
            "0.11902371793985367 -0.17974309623241425\n",
            "-0.3950834274291992 -0.2354183793067932\n",
            "0.18025198578834534 0.07018348574638367\n",
            "0.19401207566261292 0.4303884506225586\n",
            "-0.20108051598072052 -0.5286418795585632\n",
            "0.3318420350551605 -0.17050985991954803\n",
            "0.08419295400381088 -0.03767567500472069\n",
            "-0.0331692099571228 -0.055627066642045975\n",
            "-0.17959202826023102 -0.2404220849275589\n",
            "-0.0012071707751601934 0.02726668119430542\n",
            "-0.3621281683444977 0.19779525697231293\n",
            "-0.5427725315093994 -0.44666650891304016\n",
            "0.21382732689380646 0.07945261150598526\n",
            "0.36054450273513794 0.4225676953792572\n",
            "-0.0021132740657776594 -0.05360246077179909\n",
            "-0.2759667634963989 -0.2526870667934418\n",
            "-0.28701943159103394 0.02211933396756649\n",
            "-0.16814091801643372 0.10211578756570816\n",
            "0.16152667999267578 0.19555030763149261\n",
            "0.08796525001525879 -0.0801728144288063\n",
            "-0.18580804765224457 -0.20029519498348236\n",
            "0.08960213512182236 0.3098267614841461\n",
            "0.22439953684806824 0.06620854884386063\n",
            "-0.036577027291059494 -0.561303436756134\n",
            "0.6517052054405212 0.3806014955043793\n",
            "-0.048318494111299515 0.13811811804771423\n",
            "-0.12362564355134964 -0.20126229524612427\n",
            "0.3012673854827881 0.33172595500946045\n",
            "0.205556720495224 -0.12290968745946884\n",
            "-0.2631300389766693 -0.0769137367606163\n",
            "0.16977104544639587 0.2414601445198059\n",
            "0.21124471724033356 0.2483304738998413\n",
            "-0.20663680136203766 -0.36559322476387024\n",
            "-0.060224514454603195 -0.2281610518693924\n",
            "-0.19666017591953278 -0.10400557518005371\n",
            "0.22338847815990448 0.46079084277153015\n",
            "-0.37534552812576294 0.18929177522659302\n",
            "-0.01714301109313965 -0.2514480650424957\n",
            "0.3566150665283203 0.24835330247879028\n",
            "0.3623293340206146 0.15120826661586761\n",
            "0.15735910832881927 0.01935507357120514\n",
            "-0.1573016345500946 -0.1639196127653122\n",
            "0.4045476019382477 0.5183775424957275\n",
            "-0.30059751868247986 0.10213303565979004\n",
            "0.44479990005493164 0.07566390186548233\n",
            "0.2903018295764923 -0.018557315692305565\n",
            "0.055534183979034424 -0.32712265849113464\n",
            "-0.01123023871332407 0.060947027057409286\n",
            "0.32840150594711304 0.1833912879228592\n",
            "-0.20889393985271454 -0.20226503908634186\n",
            "0.1435755044221878 -0.1529286801815033\n",
            "0.1969127357006073 0.17113471031188965\n",
            "0.35603976249694824 0.004405684769153595\n",
            "-0.25309261679649353 -0.07375963777303696\n",
            "-0.03832840174436569 0.0773918405175209\n",
            "0.21322129666805267 0.30922001600265503\n",
            "-0.05986965447664261 -0.05114428699016571\n",
            "0.017522305250167847 0.24381256103515625\n",
            "-0.03669632226228714 -0.23190121352672577\n",
            "-0.1262093484401703 -0.26214632391929626\n",
            "0.2567782998085022 0.41500794887542725\n",
            "0.8427032232284546 0.8334522843360901\n",
            "0.02781759761273861 0.06302332133054733\n",
            "-0.08450199663639069 0.027998976409435272\n",
            "-0.09293307363986969 -0.38186368346214294\n",
            "-0.07828885316848755 -0.05912606790661812\n",
            "0.5243228673934937 0.540523111820221\n",
            "0.3592991232872009 -0.14585714042186737\n",
            "-0.29756399989128113 -0.37761983275413513\n",
            "0.019033504649996758 -0.20615912973880768\n",
            "-0.505729615688324 -0.1706569641828537\n",
            "-0.15651832520961761 0.11451929062604904\n",
            "-0.4187338948249817 -0.11196750402450562\n",
            "0.1237509697675705 -0.3139644265174866\n",
            "0.16360972821712494 -0.12296298146247864\n",
            "-0.226083904504776 -0.03714880719780922\n",
            "-0.023769749328494072 0.19313263893127441\n",
            "0.12006284296512604 0.26734060049057007\n",
            "-0.03204958513379097 0.08953937143087387\n",
            "0.25643303990364075 0.2584139406681061\n",
            "0.058819301426410675 -0.10148777812719345\n",
            "0.14798419177532196 0.3088829815387726\n",
            "-0.026183132082223892 0.1561036854982376\n",
            "-0.13048097491264343 -0.030555253848433495\n",
            "-0.16016817092895508 -0.1941884309053421\n",
            "-0.08311764150857925 -0.279191255569458\n",
            "0.3594260811805725 0.4293684661388397\n",
            "-0.1807277351617813 0.08071800321340561\n",
            "0.3431319296360016 0.23023933172225952\n",
            "0.1793031543493271 -0.019421935081481934\n",
            "-0.06390102207660675 -0.05388522148132324\n",
            "0.14491067826747894 0.03300800919532776\n",
            "-0.23747767508029938 -0.5449461340904236\n",
            "0.058809515088796616 0.22007642686367035\n",
            "-0.25382378697395325 -0.3943440616130829\n",
            "0.16394899785518646 0.45166656374931335\n",
            "-0.08250407129526138 0.07232023030519485\n",
            "-0.024310072883963585 -0.2231290340423584\n",
            "0.0010900369379669428 -0.6171148419380188\n",
            "-0.014909220859408379 0.3028993308544159\n",
            "0.2525726556777954 0.46119213104248047\n",
            "-0.11586243659257889 0.0053590587340295315\n",
            "0.056248631328344345 0.08306284993886948\n",
            "0.35988736152648926 0.0619654655456543\n",
            "-0.2443922609090805 -0.5558338165283203\n",
            "0.2951483130455017 0.09182307124137878\n",
            "-0.16324660181999207 0.07078903913497925\n",
            "0.0275168027728796 0.06199812516570091\n",
            "-0.007815344259142876 -0.1350417584180832\n",
            "0.16497190296649933 0.1753782033920288\n",
            "-0.15105728805065155 -0.08285170793533325\n",
            "-0.11773144453763962 -0.37963709235191345\n",
            "-0.05362923815846443 -0.3204628527164459\n",
            "0.44672006368637085 0.458457350730896\n",
            "0.20093992352485657 -0.1253758668899536\n",
            "0.24165283143520355 0.28390708565711975\n",
            "0.49997445940971375 0.25236523151397705\n",
            "0.08861629664897919 0.2801527976989746\n",
            "0.03667081147432327 -0.26528847217559814\n",
            "-0.0027723610401153564 0.2707568109035492\n",
            "-0.08343066275119781 -0.2647537291049957\n",
            "0.06017880514264107 0.20863233506679535\n",
            "0.10137716680765152 -0.035606857389211655\n",
            "-0.5913236737251282 -0.6914169788360596\n",
            "0.05317177623510361 -0.26388105750083923\n",
            "0.05841691046953201 0.11364176124334335\n",
            "-0.2404109388589859 -0.1579476147890091\n",
            "-4.086630821228027 -3.6043336391448975\n",
            "0.04730735346674919 -0.13766393065452576\n",
            "0.17710177600383759 0.21446408331394196\n",
            "-0.1337515264749527 -0.24819143116474152\n",
            "0.10962672531604767 0.1242869570851326\n",
            "-0.1970072239637375 -0.2422177791595459\n",
            "-0.08829981088638306 -0.14254121482372284\n",
            "-0.15827076137065887 -0.34883901476860046\n",
            "-0.2206784337759018 -0.04323245957493782\n",
            "0.012909735552966595 0.07936020940542221\n",
            "-0.02379031851887703 0.11046358197927475\n",
            "-0.3222120702266693 -0.14247159659862518\n",
            "0.19052603840827942 0.4305664300918579\n",
            "0.029998233541846275 0.03180757164955139\n",
            "0.1291324645280838 -0.1285770833492279\n",
            "0.038412075489759445 0.010238498449325562\n",
            "0.16317734122276306 -0.09491345286369324\n",
            "-0.16371290385723114 0.029064342379570007\n",
            "-0.13557344675064087 -0.14862947165966034\n",
            "-0.025194568559527397 0.4003724157810211\n",
            "-0.1032039001584053 0.07593686133623123\n",
            "0.05387257784605026 0.42822369933128357\n",
            "0.029708895832300186 -0.02744314633309841\n",
            "-0.2471764236688614 0.08296520262956619\n",
            "0.10688834637403488 0.1326720118522644\n",
            "0.5957538485527039 0.4767550528049469\n",
            "-0.22421933710575104 -0.29082342982292175\n",
            "-0.21229226887226105 0.1332608014345169\n",
            "0.024820907041430473 0.09884417057037354\n",
            "-0.04033655673265457 0.48854294419288635\n",
            "0.03307187557220459 -0.00880586076527834\n",
            "-0.17975714802742004 -0.2870793342590332\n",
            "-0.26425376534461975 -0.05522862449288368\n",
            "-0.307699590921402 -0.20529885590076447\n",
            "-0.013340766541659832 -0.14114883542060852\n",
            "0.09416693449020386 -0.15167845785617828\n",
            "-0.10981293767690659 0.017299115657806396\n",
            "-0.12904459238052368 0.1473480463027954\n",
            "0.13157662749290466 0.23550301790237427\n",
            "0.08455895632505417 0.3115752637386322\n",
            "-0.02115716226398945 -0.08080392330884933\n",
            "-0.20370875298976898 -0.20937730371952057\n",
            "0.19431817531585693 -0.12395850569009781\n",
            "0.006609652657061815 -0.1956353634595871\n",
            "0.5684043169021606 0.2693665027618408\n",
            "-0.06386251747608185 -0.07998540997505188\n",
            "-0.3030240833759308 -0.5593335628509521\n",
            "-0.6857281923294067 -0.688739001750946\n",
            "-0.21603573858737946 0.059804271906614304\n",
            "0.3791811764240265 0.11002686619758606\n",
            "0.30067816376686096 0.2803528308868408\n",
            "-0.316343754529953 -0.44563278555870056\n",
            "0.16603899002075195 -0.05481509491801262\n",
            "0.0787276029586792 0.2396893948316574\n",
            "0.029161402955651283 0.044585440307855606\n",
            "0.05332830175757408 0.09246786683797836\n",
            "0.3396165668964386 0.45399904251098633\n",
            "0.16577233374118805 0.640159547328949\n",
            "0.23143622279167175 0.2848667502403259\n",
            "-0.30300500988960266 -0.33694180846214294\n",
            "0.19225752353668213 -0.018690574914216995\n",
            "-0.35395804047584534 -0.4650677740573883\n",
            "-0.2048102468252182 -0.4301340878009796\n",
            "-0.03293606638908386 0.2915436029434204\n",
            "-0.3474493622779846 -0.3178212642669678\n",
            "-0.19936196506023407 -0.21965275704860687\n",
            "-0.14977039396762848 -0.2772497534751892\n",
            "-0.008788534440100193 -0.18030667304992676\n",
            "0.35829535126686096 0.08116623759269714\n",
            "0.06603748351335526 0.38306936621665955\n",
            "-0.1509571075439453 -0.1684088259935379\n",
            "-0.05394742265343666 0.07310644537210464\n",
            "-0.4196590781211853 -0.013994157314300537\n",
            "-0.8773579001426697 -0.9461310505867004\n",
            "-0.5218543410301208 -0.6598374247550964\n",
            "-0.0916232243180275 -0.33923104405403137\n",
            "-0.07695106416940689 -0.15419037640094757\n",
            "-0.08438555151224136 -0.024086803197860718\n",
            "0.5525056719779968 0.5006847977638245\n",
            "-0.1973603069782257 -0.2500108778476715\n",
            "-0.24581031501293182 -0.2753760814666748\n",
            "-0.23780904710292816 -0.12570230662822723\n",
            "0.3721155822277069 0.11192518472671509\n",
            "-0.08000516146421432 -0.15206168591976166\n",
            "-0.07926888763904572 0.1894807368516922\n",
            "-0.379897803068161 -0.15191419422626495\n",
            "0.15432004630565643 0.3441048562526703\n",
            "0.011698408983647823 -0.03769861161708832\n",
            "0.15765714645385742 0.14436744153499603\n",
            "-0.2428593933582306 -0.4582919776439667\n",
            "0.3436315655708313 0.40156078338623047\n",
            "-0.09194327145814896 -0.25428780913352966\n",
            "-0.2196962833404541 -0.07237634062767029\n",
            "0.06753575801849365 -0.23868894577026367\n",
            "0.16522826254367828 0.32903316617012024\n",
            "0.27246543765068054 0.3955167233943939\n",
            "-0.16969510912895203 -0.14108531177043915\n",
            "-0.2786850929260254 -0.04530304670333862\n",
            "-0.046642739325761795 -0.13261401653289795\n",
            "0.1831616461277008 -0.1029362604022026\n",
            "-0.2045171558856964 -0.11383521556854248\n",
            "-0.3701688349246979 -0.3628993034362793\n",
            "0.18069961667060852 0.27608567476272583\n",
            "0.007494715508073568 -0.08279353380203247\n",
            "0.42040231823921204 0.30386948585510254\n",
            "0.3295688033103943 0.12286544591188431\n",
            "-0.18839414417743683 -0.43203482031822205\n",
            "0.07580821961164474 0.1497276872396469\n",
            "-0.39944663643836975 -0.26158347725868225\n",
            "0.16786286234855652 0.1506601870059967\n",
            "-0.048957135528326035 0.03463095426559448\n",
            "-0.4486289322376251 -0.3561640679836273\n",
            "0.44659551978111267 0.21135257184505463\n",
            "-0.17123213410377502 -0.038696322590112686\n",
            "0.04615914821624756 -0.06615892797708511\n",
            "-0.07975252717733383 -0.1924215406179428\n",
            "0.15288104116916656 0.10501659661531448\n",
            "0.2692566215991974 0.3769376575946808\n",
            "0.0046113645657896996 0.23425163328647614\n",
            "0.046293407678604126 0.1591378003358841\n",
            "-0.0966559648513794 0.008586034178733826\n",
            "0.3282375931739807 0.08718752861022949\n",
            "-0.22187016904354095 -0.047809530049562454\n",
            "-0.1527949720621109 -0.1309387981891632\n",
            "-0.27423205971717834 -0.02096054144203663\n",
            "0.00538650993257761 -0.20629467070102692\n",
            "-0.38539543747901917 -0.18676869571208954\n",
            "-0.11197701841592789 -0.1812199354171753\n",
            "-0.0625767633318901 0.04460650682449341\n",
            "-0.09752251207828522 -0.11493285745382309\n",
            "0.20974114537239075 -0.1410972625017166\n",
            "-0.21095295250415802 -0.2850886583328247\n",
            "-0.1702706515789032 0.08049174398183823\n",
            "-0.08172111213207245 -0.0012230625143274665\n",
            "0.009529064409434795 -0.048811864107847214\n",
            "0.2767222821712494 0.3706932067871094\n",
            "0.18569044768810272 0.24729318916797638\n",
            "-0.2920549809932709 -0.34395384788513184\n",
            "0.001740808947943151 -0.12306194752454758\n",
            "0.12123117595911026 0.3155602812767029\n",
            "0.01337389461696148 -0.06243058666586876\n",
            "-0.14442399144172668 0.2827928960323334\n",
            "-0.30157867074012756 -0.4012329578399658\n",
            "0.16775314509868622 0.36058568954467773\n",
            "-0.24146874248981476 -0.4745410680770874\n",
            "0.12087862938642502 0.3690234422683716\n",
            "-0.8224149346351624 -0.3494982421398163\n",
            "0.06091867759823799 -0.018901636824011803\n",
            "0.02306198701262474 -0.07381988316774368\n",
            "0.028242090716958046 -0.135517880320549\n",
            "0.06923337280750275 -0.04500637948513031\n",
            "-0.356962651014328 -0.3482566177845001\n",
            "0.16329887509346008 -0.00017834950995165855\n",
            "-0.31281524896621704 -0.34685564041137695\n",
            "0.0054121422581374645 -0.16414599120616913\n",
            "-0.16523012518882751 -0.3993913233280182\n",
            "0.12051345407962799 0.10224928706884384\n",
            "0.010520391166210175 -0.08393485099077225\n",
            "-0.5337902307510376 -0.27815595269203186\n",
            "0.127364844083786 -0.22341877222061157\n",
            "-0.026115616783499718 -0.2518216669559479\n",
            "0.13623759150505066 0.05763384699821472\n",
            "-0.006323439534753561 -0.10083527117967606\n",
            "0.07425333559513092 0.05669618025422096\n",
            "-0.23094554245471954 0.22746090590953827\n",
            "0.0246274471282959 -0.15687060356140137\n",
            "0.09811121970415115 0.1285892128944397\n",
            "-0.1959897130727768 -0.18168556690216064\n",
            "-0.16574819386005402 -0.14571107923984528\n",
            "0.610405445098877 0.5862636566162109\n",
            "0.016319002956151962 -0.012691478244960308\n",
            "-0.2602596879005432 -0.24080413579940796\n",
            "0.1423395425081253 -0.05024336650967598\n",
            "-0.03617284819483757 -0.013686825521290302\n",
            "-0.02683558501303196 -0.11829852312803268\n",
            "0.21074996888637543 0.23569434881210327\n",
            "0.4073677659034729 0.05361780524253845\n",
            "0.20193730294704437 -0.166389599442482\n",
            "-0.20648063719272614 -0.1112673282623291\n",
            "-0.11341732740402222 0.12180031090974808\n",
            "-0.04354837164282799 -0.1912347823381424\n",
            "0.06637891381978989 0.2941322326660156\n",
            "-0.25417211651802063 0.20608092844486237\n",
            "-0.20827917754650116 0.2743537127971649\n",
            "0.13512316346168518 0.2985427677631378\n",
            "0.04466373100876808 0.018618514761328697\n",
            "0.10886126011610031 0.19131343066692352\n",
            "-0.43016862869262695 -0.33404088020324707\n",
            "0.31580203771591187 0.32839691638946533\n",
            "0.051892757415771484 0.0029271456878632307\n",
            "0.27709218859672546 -0.06544622033834457\n",
            "0.19440777599811554 0.23419226706027985\n",
            "-0.10310109704732895 0.170187309384346\n",
            "0.02143302746117115 -0.1399100422859192\n",
            "-0.21649643778800964 -0.08620783686637878\n",
            "-0.14621448516845703 -0.20150695741176605\n",
            "0.11195914447307587 0.3629857003688812\n",
            "-0.02842198871076107 -0.17091910541057587\n",
            "0.010824833996593952 0.1624458134174347\n",
            "0.25726982951164246 0.20400674641132355\n",
            "0.18067725002765656 0.5197618007659912\n",
            "-0.02349003776907921 -0.15925881266593933\n",
            "-0.07911434024572372 -0.06789875775575638\n",
            "0.030559947714209557 0.020682839676737785\n",
            "-0.2819376587867737 0.02955862320959568\n",
            "-0.05868958681821823 0.31599119305610657\n",
            "0.04017972946166992 0.0634937658905983\n",
            "0.016590043902397156 -0.07567612081766129\n",
            "0.05186455696821213 -0.14515239000320435\n",
            "0.013090661726891994 -0.06132970377802849\n",
            "-0.4892813563346863 -0.30231115221977234\n",
            "0.021633105352520943 -0.065151147544384\n",
            "-0.2148798257112503 -0.36350706219673157\n",
            "-0.1620785892009735 -0.13230639696121216\n",
            "-0.028328631073236465 -0.13470540940761566\n",
            "-0.22724367678165436 0.2581108808517456\n",
            "0.08839811384677887 0.24929070472717285\n",
            "0.1030082032084465 0.22727565467357635\n",
            "-0.034061260521411896 -0.09969005733728409\n",
            "0.03819431737065315 0.3084396719932556\n",
            "-0.16283893585205078 -0.4277963638305664\n",
            "-0.191593736410141 -0.22684352099895477\n",
            "0.20180603861808777 -0.03225718066096306\n",
            "0.1655929982662201 -0.09622302651405334\n",
            "-0.3187773525714874 -0.3226689398288727\n",
            "-0.6130543947219849 -0.27293625473976135\n",
            "0.10590071231126785 0.26345038414001465\n",
            "-0.2576991021633148 -0.05729871988296509\n",
            "-0.19204674661159515 -0.3964881896972656\n",
            "-0.17745839059352875 -0.08307680487632751\n",
            "0.09330153465270996 0.5221931338310242\n",
            "-0.08411329239606857 -0.25450780987739563\n",
            "-0.12731638550758362 -0.2279708832502365\n",
            "0.030247140675783157 -0.013994530774652958\n",
            "-0.07730177789926529 0.1649654656648636\n",
            "0.15745757520198822 0.27403387427330017\n",
            "0.27232369780540466 0.07091055065393448\n",
            "-0.466207355260849 -0.02900196611881256\n",
            "-0.33771416544914246 -0.01568499393761158\n",
            "0.20893000066280365 -0.02742503397166729\n",
            "0.10710626095533371 -0.013480489142239094\n",
            "-0.029572879895567894 -0.15677081048488617\n",
            "-0.02683948166668415 0.04432274028658867\n",
            "-0.27065640687942505 -0.33758559823036194\n",
            "0.11143116652965546 -0.16417229175567627\n",
            "-0.2090376317501068 -0.024933138862252235\n",
            "0.4842495918273926 0.31766173243522644\n",
            "0.14861105382442474 -0.03095743991434574\n",
            "0.07529540359973907 0.15016581118106842\n",
            "0.3159863352775574 -0.028341948986053467\n",
            "-0.059448666870594025 -0.05672958865761757\n",
            "0.2932550311088562 0.4550049304962158\n",
            "0.13422712683677673 0.23435425758361816\n",
            "-0.18118537962436676 -0.17688031494617462\n",
            "0.0649891123175621 0.24603603780269623\n",
            "0.0247234795242548 0.11403951048851013\n",
            "-0.07346052676439285 0.03762902691960335\n",
            "0.2007489651441574 0.3549743592739105\n",
            "0.04594579339027405 -0.340647429227829\n",
            "-0.15641067922115326 -0.10240122675895691\n",
            "-0.24634583294391632 -0.500604510307312\n",
            "0.058708686381578445 0.3119329512119293\n",
            "-0.08098465949296951 -0.035164907574653625\n",
            "0.20607729256153107 0.42835187911987305\n",
            "0.03798549622297287 0.20177936553955078\n",
            "0.04042787477374077 -0.090561144053936\n",
            "0.2358580082654953 0.19703543186187744\n",
            "0.15901270508766174 0.18786375224590302\n",
            "-0.09561026841402054 0.03731558099389076\n",
            "-0.20926769077777863 -0.18819479644298553\n",
            "-0.4383494257926941 -0.3442542552947998\n",
            "0.08663124591112137 -0.03524506464600563\n",
            "0.18500696122646332 -0.29981276392936707\n",
            "-0.1455124467611313 0.23104600608348846\n",
            "-0.06737273186445236 -0.1474941223859787\n",
            "-0.21592357754707336 -0.08571553975343704\n",
            "0.14262627065181732 -0.3473873436450958\n",
            "-0.19001172482967377 -0.21544963121414185\n",
            "0.07234640419483185 -0.07389327138662338\n",
            "-0.25307542085647583 -0.1802925318479538\n",
            "0.09645901620388031 0.15921597182750702\n",
            "0.12023388594388962 0.11024149507284164\n",
            "-0.11048015207052231 -0.13907255232334137\n",
            "0.17570467293262482 -0.08962976932525635\n",
            "-0.16867640614509583 -0.03144257515668869\n",
            "0.05804147198796272 -0.002960801124572754\n",
            "0.16506484150886536 -0.043930232524871826\n",
            "0.1384250372648239 -0.07162763923406601\n",
            "-0.04207732155919075 -0.0911797359585762\n",
            "-0.44255080819129944 -0.3353312015533447\n",
            "0.00922978762537241 0.2906254529953003\n",
            "0.24021506309509277 -0.0642218068242073\n",
            "0.1635279357433319 0.14323531091213226\n",
            "0.05731693655252457 -0.13051597774028778\n",
            "0.12389160692691803 -0.29202309250831604\n",
            "-0.0007250979542732239 0.06463668495416641\n",
            "0.6170517802238464 0.20537543296813965\n",
            "0.24624435603618622 0.13958902657032013\n",
            "0.28145870566368103 -0.07342644780874252\n",
            "-0.2890358865261078 -0.21533489227294922\n",
            "-0.3715430200099945 -0.4584942162036896\n",
            "-0.0038752215914428234 0.28485116362571716\n",
            "0.12037629634141922 0.22793573141098022\n",
            "0.1749032586812973 0.18473081290721893\n",
            "-0.16659153997898102 -0.2330838292837143\n",
            "0.09252165257930756 0.5238283276557922\n",
            "-0.11256366223096848 -0.4259707033634186\n",
            "-0.20514130592346191 -0.01682867296040058\n",
            "-0.07166492938995361 -0.5446654558181763\n",
            "0.10160370916128159 -0.13000938296318054\n",
            "0.27108463644981384 0.045077696442604065\n",
            "-0.19477413594722748 -0.3625541925430298\n",
            "0.07343968003988266 0.07234811782836914\n",
            "0.1189652532339096 0.20442020893096924\n",
            "-0.32108157873153687 -0.38103970885276794\n",
            "-0.06031382083892822 0.04908517003059387\n",
            "-0.11929885298013687 0.27275773882865906\n",
            "-0.4804539680480957 -0.09348449856042862\n",
            "-0.47968053817749023 -0.30725064873695374\n",
            "0.25244539976119995 0.21780799329280853\n",
            "-0.16757357120513916 0.43149110674858093\n",
            "0.02943999692797661 -0.11326561123132706\n",
            "0.3894708454608917 0.17856603860855103\n",
            "0.34106165170669556 0.2863736152648926\n",
            "0.3230641782283783 0.32133758068084717\n",
            "0.3483319580554962 0.1980847269296646\n",
            "-0.46684545278549194 -0.5587775111198425\n",
            "0.3254430890083313 0.10583054274320602\n",
            "0.07975268363952637 0.029085226356983185\n",
            "0.20156030356884003 0.18547506630420685\n",
            "0.21160422265529633 -0.12568867206573486\n",
            "0.03521883487701416 -0.05305755138397217\n",
            "-0.2387610822916031 -0.2965446710586548\n",
            "0.6123225092887878 0.7141172289848328\n",
            "-0.2613997161388397 -0.3591921627521515\n",
            "-0.2821902930736542 -0.28029704093933105\n",
            "-0.1581958681344986 -0.15976785123348236\n",
            "0.017819205299019814 -0.0710156187415123\n",
            "0.4005127549171448 0.07692161947488785\n",
            "-0.17711268365383148 -0.12006811052560806\n",
            "-0.3081003725528717 0.039662525057792664\n",
            "0.3020017743110657 0.05586078763008118\n",
            "-0.11712940782308578 -0.20805110037326813\n",
            "0.6181893348693848 0.44809094071388245\n",
            "0.07349880039691925 -0.2780224680900574\n",
            "0.3161751925945282 0.2798011898994446\n",
            "-0.14140766859054565 0.08103238791227341\n",
            "-0.39189812541007996 -0.3103754222393036\n",
            "0.331489622592926 0.43918919563293457\n",
            "0.42831358313560486 0.2716391384601593\n",
            "0.2362344115972519 0.17470477521419525\n",
            "-0.019726095721125603 0.22652201354503632\n",
            "-0.2610659599304199 -0.09298083186149597\n",
            "-0.21354106068611145 -0.13735419511795044\n",
            "0.0305167268961668 -0.20275254547595978\n",
            "0.24452121555805206 0.08098149299621582\n",
            "0.21113288402557373 0.1785212755203247\n",
            "0.3310365378856659 0.16341346502304077\n",
            "-0.3803560435771942 -0.38756629824638367\n",
            "-0.23061461746692657 -0.4235781133174896\n",
            "-0.21030302345752716 -0.45848408341407776\n",
            "-0.376198947429657 -0.17561419308185577\n",
            "0.2656678855419159 0.32122501730918884\n",
            "-0.19771382212638855 -0.35095441341400146\n",
            "-0.13247276842594147 0.06674083322286606\n",
            "0.43842124938964844 0.5071528553962708\n",
            "-0.19188807904720306 -0.4583229124546051\n",
            "-0.31375885009765625 -0.42648282647132874\n",
            "0.0341799333691597 0.10356239229440689\n",
            "0.28516238927841187 0.10716003179550171\n",
            "0.05662718042731285 0.12921488285064697\n",
            "0.23051942884922028 0.3338186740875244\n",
            "-0.144247904419899 -0.07921150326728821\n",
            "-0.20703747868537903 -0.34074246883392334\n",
            "-0.5206007957458496 -0.1440892517566681\n",
            "0.5520071387290955 0.5771172642707825\n",
            "-0.14669838547706604 -0.43543222546577454\n",
            "-0.12562906742095947 -0.04527219757437706\n",
            "-0.06385745853185654 -0.44613727927207947\n",
            "0.21206195652484894 -0.11972001940011978\n",
            "0.21495261788368225 -0.17961366474628448\n",
            "0.10164313018321991 0.04386952519416809\n",
            "-0.16602085530757904 0.072306327521801\n",
            "-0.028239000588655472 0.2490321397781372\n",
            "0.14431706070899963 0.25999704003334045\n",
            "-0.17713890969753265 -0.008560056798160076\n",
            "0.12670812010765076 -0.18706341087818146\n",
            "0.15587298572063446 -0.024417152628302574\n",
            "0.014463631436228752 -0.30710190534591675\n",
            "-0.3542254865169525 -0.490926057100296\n",
            "0.33929941058158875 0.27213630080223083\n",
            "-0.36658257246017456 -0.07374673336744308\n",
            "0.07691485434770584 0.10175184160470963\n",
            "-0.04759756848216057 -0.041681621223688126\n",
            "0.0592365637421608 0.2377636581659317\n",
            "-0.37528374791145325 -0.2946588695049286\n",
            "0.30268004536628723 0.1919669359922409\n",
            "0.06198844686150551 0.21058784425258636\n",
            "0.402360200881958 0.29659131169319153\n",
            "0.13390962779521942 0.08888301998376846\n",
            "0.17103615403175354 0.06072525680065155\n",
            "-0.14543333649635315 -0.36946842074394226\n",
            "0.0030547294300049543 -0.13060997426509857\n",
            "0.14524081349372864 0.2816751301288605\n",
            "0.18735109269618988 0.11484956741333008\n",
            "0.030666816979646683 -0.3387279212474823\n",
            "0.38756826519966125 0.1177077665925026\n",
            "0.16975067555904388 0.3662576675415039\n",
            "-0.12099238485097885 -0.36955419182777405\n",
            "-0.04941767826676369 -0.11566797643899918\n",
            "-0.1395471841096878 0.046143289655447006\n",
            "0.0025372335221618414 0.052305251359939575\n",
            "-1.0310403108596802 -1.203297734260559\n",
            "-0.05921701714396477 -0.06176235154271126\n",
            "-0.07237625867128372 -0.19153320789337158\n",
            "0.07051335275173187 0.0882633700966835\n",
            "-0.16319309175014496 -0.03155052289366722\n",
            "0.15141558647155762 0.27590182423591614\n",
            "0.13665200769901276 0.022428395226597786\n",
            "0.29141730070114136 -0.14837895333766937\n",
            "-0.2631877660751343 -0.02364506758749485\n",
            "-0.1463046371936798 -0.28843459486961365\n",
            "-0.256420373916626 -0.15082450211048126\n",
            "0.10480998456478119 0.3201500475406647\n",
            "-0.2330867201089859 -0.3984968960285187\n",
            "0.4607238471508026 0.46152088046073914\n",
            "0.2012210190296173 0.1159307062625885\n",
            "0.2762743830680847 0.31325581669807434\n",
            "-0.20183391869068146 0.08358518034219742\n",
            "-0.23522236943244934 0.09431203454732895\n",
            "0.2675345838069916 0.2691008746623993\n",
            "0.32758745551109314 0.12816639244556427\n",
            "-0.13564050197601318 0.15220922231674194\n",
            "-0.09927032142877579 0.07282034307718277\n",
            "0.14964677393436432 0.3914521038532257\n",
            "-0.15633344650268555 -0.7510927319526672\n",
            "-0.09635327756404877 0.18074624240398407\n",
            "-0.17374394834041595 -0.11045519262552261\n",
            "-0.3893783390522003 -0.5116342902183533\n",
            "-0.3389112055301666 -0.2507542371749878\n",
            "0.14394168555736542 -0.037553124129772186\n",
            "-0.00030648495885543525 0.003140882821753621\n",
            "0.40982455015182495 0.6577778458595276\n",
            "-0.18129944801330566 -0.04105394333600998\n",
            "-1.2549444437026978 -1.3953005075454712\n",
            "-0.20116470754146576 0.006621956825256348\n",
            "-0.33278271555900574 0.0946745052933693\n",
            "-0.5120208859443665 -0.8113047480583191\n",
            "0.30114272236824036 0.2396910935640335\n",
            "-0.033678315579891205 0.008101814426481724\n",
            "0.059071559458971024 0.5043144822120667\n",
            "-0.23494383692741394 -0.27852001786231995\n",
            "-0.21624180674552917 0.036456767469644547\n",
            "-0.4435219168663025 -0.6516817212104797\n",
            "-0.19866253435611725 -0.344586044549942\n",
            "-0.016398098319768906 -0.059887323528528214\n",
            "0.386563777923584 0.39160189032554626\n",
            "-0.1726774126291275 -0.3290138840675354\n",
            "-0.00514883641153574 0.13994841277599335\n",
            "0.12390480190515518 0.05298146605491638\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}